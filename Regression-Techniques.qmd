---
title: "Regression Techniques"
format: 
  html:
    embed-resources: true
---

```{r}
library(magrittr)
library(tidyverse)
library(ISLR2)
```

Collecting a set of data (n = 100 observations) containing a single predictor and a quantitative response.

```{r}
set.seed(777)
X <- rnorm(100)
Y <- 7*X + rnorm(100)

```

Fitting a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 +β1X +β2X2 +β3X3 +ε.

```{r}
linear_model <- lm(Y ~ X)

cubic_model <- lm(Y ~ poly(X, 3))
```

```{r}
linear_predicted <- predict(linear_model)
linear_residuals <- Y - linear_predicted  
linear_RSS <- sum(linear_residuals^2) 
linear_RSS

cubic_predicted <- predict(cubic_model)  
cubic_residuals <- Y - cubic_predicted  
cubic_RSS <- sum(cubic_residuals^2)  
cubic_RSS
```
**It seems as tough RSS for cubic regression is lower than the linear regression. Another test:**

```{r}
anova(linear_model, cubic_model)
```


```{r}
linear_predicted <- predict(linear_model)
linear_residuals <- Y - linear_predicted  
linear_RSS <- sum(linear_residuals^2) 
linear_RSS

cubic_predicted <- predict(cubic_model)  
cubic_residuals <- Y - cubic_predicted  
cubic_RSS <- sum(cubic_residuals^2)  
cubic_RSS
```
**Lower RSS for cubic model. Now, another test:**

```{r}
anova(linear_model, cubic_model)
```

** Using built-in Auto data set. **

**Performing a simple linear regression with mpg as the response, and horsepower as the predictor.

```{r}
fit <- lm(mpg ~ horsepower, data = Auto)
summary(fit)
```

**There is a relationship because p value is less than 0.05. It is a very strong relationship because it has \*\*\* (three stars) next to it, meaning that p value is between 0 and 0.001, which is very less than 0.05.The less the p-value is, there is more significance.**

**The relationship is negative because the estimator is less than zero.**

**Predicted mpg associated with a horsepower of 98, and associated 95 % confidence and prediction intervals:*

```{r}
predict(fit, newdata = data.frame(horsepower = 98), interval = "prediction", level = 0.95)

predict(fit, newdata = data.frame(horsepower = 98), interval = "confidence", level = 0.95)

```
**The predicted mpg associated with a horsepower of 98 is 24.46708.**

**The prediction interval suggests that we are 95% confident that the mpg at horsepower of 98 is between 14.8094 and 34.12476.The confidence interval suggests that we are 95% confident that the 'true expected value' of mpg at horsepower of 98 is between 23.97308 to 24.96108.**

**Plotting the response and the predictor. Using the abline() function to display the least squares regression line.**

```{r}
plot(Auto$horsepower,Auto$mpg, col = "magenta")
abline(abline(fit, col = "blue"))
```

**Producing diagnostic plots of the least squares regression fit:**

```{r}
par(mfrow = c(2,2))
plot(fit)
```

**A U-shaped or curved pattern in the residuals might suggest nonlinearity in the model, indicating that a linear regression model may not be the best fit for the data.**

**If the residuals closely follow a normal distribution, the points on the Q-Q plot should fall approximately along a straight line at a 45-degree angle. Hence, the second graph demonstrates that the residuals follow a normal distribution.**

**Ideally, the points on the plot should form a horizontal band or a roughly constant spread around the central line, which means that the the variability in errors remains consistent.**

**Finally, the fourth graph indicates that there are no significant data points or outliers that are affecting the model**

** Performing cross-validation on a simulated data set.**

```{=html}
<!-- -->
```
**Generating a simulated data set as follows:**

```{r}
set.seed(1)
x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)
```

```{r}
plot(x,y)
```

**The plot results as a curve shape as expected because the biggest power i the equation is 2, which is squared and it results in a curved shape.**

```{r}
library(boot)
set.seed(90)
data <- data.frame(x, y)
fit1 <- glm(y ~ x)
cv.glm(data, fit1)$delta[1]
```

```{r}
fit2 <- glm(y ~ poly(x, 2))
cv.glm(data, fit2)$delta[1]
```

```{r}
fit3 <- glm(y ~ poly(x, 3))
cv.glm(data, fit3)$delta[1]
```

```{r}
fit4 <- glm(y ~ poly(x, 4))
cv.glm(data, fit4)$delta[1]
```

**They are the same because in LOOCV, you'll obtain the same results regardless of the random seed because the process itself is not based on randomization. Each data point is treated the same way in each run, leading to a deterministic outcome.**

**The second one hsd the smallest LOOCV error and that because the optimal model is with a polynomial degree 2.**

```{r}
summary(fit4)
```

**Looking at the p-values, it is seen that the first and the second models have p-values less than 0.05 and values very close to zero. This means that they are statistically significant. The lowest LOOCV error belongs to the second model, which aligns with statistical significance. However, the first model has a high LOOCV error, which does not agree with this statistical significance.**
